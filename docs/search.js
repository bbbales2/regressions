window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "rat", "modulename": "rat", "qualname": "", "type": "module", "doc": "<p>Rat is an attempt to build an easy to use regression syntax, particularly\nfocused on player skill models. It is similar in theme to the many fine\nregression packages (lm, lme4, rstanarm, brms, etc.), but tries to take\nits own twist on the problem.</p>\n\n<p>Some central Rat features are:</p>\n\n<ol>\n<li>Parameters are named explicitly</li>\n<li>Parameters are defined by their use</li>\n<li>Long-form dataframes are the data structure for everything (data and parameters)</li>\n</ol>\n\n<p>Some central technical pieces are:</p>\n\n<ol>\n<li>Rat uses a No-U-Turn-Sampler (implementation from <a href=\"https://github.com/blackjax-devs/blackjax/tree/main/blackjax\">blackjax</a>)</li>\n<li>Rat uses autodiff from <a href=\"https://github.com/google/jax\">jax</a></li>\n</ol>\n\n<p>Rat works in a limited language space to keep the backend stuff simple\n(no sampling discrete parameters and no loops).</p>\n\n<h1 id=\"language\">Language</h1>\n\n<h2 id=\"anatomy-of-a-rat-program\">Anatomy of a Rat (program)</h2>\n\n<p>There are two full Rat examples included with the repo that are worth glancing at.\nThe first (<a href=\"https://github.com/bbbales2/regressions/tree/main/examples/mrp\">examples/mrp</a>)\nis an MRP example ported from\n<a href=\"https://bookdown.org/jl5522/MRP-case-studies/introduction-to-mrp.html\">MRP Case Studies</a>.</p>\n\n<p>The second (<a href=\"https://github.com/bbbales2/regressions/tree/main/examples/fakeball\">examples/fakeball</a>)\nis an attempt to simulate some fake basketball-like data and estimate player on-off\neffectiveness numbers.</p>\n\n<p>The example folders contain information on how to run these models, but a quick look at\nthe second model might be useful to see where we're going with all this:</p>\n\n<pre><code># We're modeling whether or not shots were made as a function of the time\n# varying skill of the five players playing offense and the five players\n# playing defense. `made`, `date`, `o0-o4`, and `d0-d4` come from the input,\n# dataframe. o0-o4 and d0-d4 are names of the five players on the floor\n# playing offense and defense\nmade ~ bernoulli_logit(\n    offense[o0, date] + offense[o1, date] + offense[o2, date] + offense[o3, date] + offense[o4, date] -\n    (defense[d0, date] + defense[d1, date] + defense[d2, date] + defense[d3, date] + defense[d4, date])\n);\n\n# A player's skill is a function of their initial skill plus some random\n# walk that changes over time\noffense[player, date] = offense0[player] + offense_rw[player, date];\ndefense[player, date] = defense0[player] + defense_rw[player, date];\n\n# Parameters are defined by use -- we need to define offense0 and defense0\n# because they are used elsewhere\noffense0[player] ~ normal(0.0, tau0_offense);\ndefense0[player] ~ normal(0.0, tau0_defense);\n\n# This is the random walk -- read on to understand how `shift` actually works\noffense_rw[player, date] ~ normal(offense_rw[player, shift(date, 1)], tau_offense);\ndefense_rw[player, date] ~ normal(defense_rw[player, shift(date, 1)], tau_defense);\n\n# Some parameters have constraints!\ntau_offense&lt;lower = 0.0&gt; ~ log_normal(0.0, 0.5);\ntau_defense&lt;lower = 0.0&gt; ~ log_normal(0.0, 0.5);\ntau0_offense&lt;lower = 0.0&gt; ~ log_normal(0.0, 0.5);\ntau0_defense&lt;lower = 0.0&gt; ~ log_normal(0.0, 0.5);\n</code></pre>\n\n<p>Assuming we've saved appropriate data in a file <code>shots.csv</code>, then a model like this can\nbe run on the command-line (or from Python, but the command line is convenient for\nthis sort of thing):</p>\n\n<pre><code>rat fakeball.rat shots.csv samples\n</code></pre>\n\n<p>The output can be extracted and summarized in Python like:</p>\n\n<div class=\"codehilite\"><pre><span></span><code><span class=\"kn\">from</span> <span class=\"nn\">rat.fit</span> <span class=\"kn\">import</span> <span class=\"n\">load</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span>\n\n<span class=\"c1\"># Rat fits are serialized as parquet tables in folders</span>\n<span class=\"n\">fit</span> <span class=\"o\">=</span> <span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s2\">&quot;samples&quot;</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Each parameter is stored in its own table -- these can be joined together</span>\n<span class=\"c1\"># or summarized on their own</span>\n<span class=\"n\">offense_df</span> <span class=\"o\">=</span> <span class=\"n\">fit</span><span class=\"o\">.</span><span class=\"n\">draws</span><span class=\"p\">(</span><span class=\"s2\">&quot;offense&quot;</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># In this case we can build a table mapping player, date tuples to parameter</span>\n<span class=\"c1\"># summaries</span>\n<span class=\"n\">offense_summary_df</span> <span class=\"o\">=</span> <span class=\"p\">(</span>\n    <span class=\"n\">offense_df</span>\n    <span class=\"o\">.</span><span class=\"n\">groupby</span><span class=\"p\">([</span><span class=\"s2\">&quot;player&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;date&quot;</span><span class=\"p\">])</span>\n    <span class=\"o\">.</span><span class=\"n\">agg</span><span class=\"p\">(</span>\n        <span class=\"n\">median</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s2\">&quot;offense&quot;</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">median</span><span class=\"p\">),</span>\n        <span class=\"n\">q10</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s2\">&quot;offense&quot;</span><span class=\"p\">,</span> <span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">quantile</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"mf\">0.1</span><span class=\"p\">)),</span>\n        <span class=\"n\">q90</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s2\">&quot;offense&quot;</span><span class=\"p\">,</span> <span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">quantile</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"mf\">0.9</span><span class=\"p\">)),</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">)</span>\n</code></pre></div>\n\n<h2 id=\"likelihood\">Likelihood</h2>\n\n<p>Every Rat program comes with a dataframe. The dataframe defines the data which\nthe Rat model fits itself to.</p>\n\n<p>Rat programs are broken up into statements separated by semicolons. There are\ntwo types of statements, sampling statements (those where the lefthand side\nand righthand side are separated by <code>~</code>) and assignments (the lefthand side\nand righthand side are separated by <code>=</code>).</p>\n\n<p>Sampling statements come in two varieties, likelihoods and priors. Likelihoods\nare the sampling statements where the variable name on the left hand side of the\n<code>~</code> comes from the input dataframe (and priors are the other ones). This section\ndiscusses the basics of likelihood statements. Priors and assignments are discussed\nlater (under section <a href=\"#priors\">Priors</a> and <a href=\"#transformed-parameters\">Transformed Parameters</a>).</p>\n\n<p>Assume we have the following dataframe:</p>\n\n<pre><code>    game_id  home_score  away_score home_team away_team  score_diff  year\n0         1         117          88       CLE       NYK        29.0  2016\n1         2         113         104       POR       UTA         9.0  2016\n2         3         100         129       GSW       SAS       -29.0  2016\n3         4          96         108       ORL       MIA       -12.0  2016\n4         5         130         121       IND       DAL         9.0  2016\n5         6         122         117       BOS       BKN         5.0  2016\n6         7         109          91       TOR       DET        18.0  2016\n7         8          96         107       MIL       CHA       -11.0  2016\n8         9         102          98       MEM       MIN         4.0  2016\n9        10         102         107       NOP       DEN        -5.0  2016\n10       11          97         103       PHI       CLE        -6.0  2016\n</code></pre>\n\n<p>The first line of a Rat program modeling this data might be:</p>\n\n<pre><code>score_diff ~ normal(skill[home_team], sigma);\n</code></pre>\n\n<p>Because this is a sampling statement (the <code>~</code>) and name on the lefthand side\nis in the dataframe, this is a likelihood statement.</p>\n\n<p>This says model <code>score_diff</code> (the score difference between the home and away teams for a\nhandful of games in the 2016 NBA season) as a normally distributed random variable given\na mean <code>skill[home_team]</code> and standard deviation <code>sigma</code>. There will be one\nterm in the likelihood for every row in the dataframe (so each row corresponds\nto a conditionally independent term).</p>\n\n<p>The other column of the dataframe that is being used is <code>home_team</code>. If we\nlook back at the dataframe, <code>home_team</code> is a string identifying which NBA\nteam was playing at home in each game. In the model it appears in brackets\nafter the variable <code>skill</code> -- in Rat terms <code>home_team</code> <em>subscripts</em> <code>skill</code>.\nThis means for each row of the input dataframe, take the entry of the variable\nskill that corresponds to the value of <code>home_team</code>.</p>\n\n<p>Because <code>skill</code> is subscripted (and is not a column in the dataframe), Rat\ninfers that it is a parameter in the model. There will be as many unique\nelements of <code>skill</code> as there are unique elements of <code>home_team</code>, because\nthis is exactly how many parameters need to exist to evaluate the likelihood.</p>\n\n<p>Because <code>sigma</code> is not a column in the dataframe, Rat infers it is a parameter.\nBecause it is not subscripted, Rat infers it is a scalar parameter.</p>\n\n<h2 id=\"priors\">Priors</h2>\n\n<p>Priors in Rat are sampling statements that are not likelihoods (the name on the\nleft hand side does not appear in the input dataframe). Priors cannot reference\ncolumns of the input dataframe (it's an error).</p>\n\n<p>The above example can be extended to have a prior on <code>skill</code>:</p>\n\n<pre><code>score_diff ~ normal(skill[home_team], sigma);\nskill[home_team] ~ normal(0.0, tau);\n</code></pre>\n\n<p>The first line defines <code>skill</code> by its use (it is a parameter with as many entries\nas there are unique values of <code>home_team</code>). The second line says, for any entry of\nskill, use a normal with standard deviation <code>tau</code>. Because <code>tau</code> is not used\nanywhere yet, Rat will infer that it is a new scalar random variable.</p>\n\n<p>The <code>home_team</code> subscript on the second line <em>matches</em> the subscript in the original\nuse. In the example above, this probably seems extraneous, but it is useful in more\ncomplex cases. First consider a two-sided skill model:</p>\n\n<pre><code>score_diff ~ normal(skill[home_team] - skill[away_team], sigma);\nskill[team] ~ normal(0.0, tau);\n</code></pre>\n\n<p>In this case, <code>skill</code> is subscripted both by <code>home_team</code> and <code>away_team</code> and\nthere will be as many elements of <code>skill</code> as required in both cases (it's possible\nsome teams only played away games -- perhaps we're running this regression early in the\nyear). This leads to the question -- how should the first subscript of <code>skill</code> be\nreferenced? It is not obvious, and so when the prior is defined, the subscripts\nare matched by position and we provide a new name. The first subscript to <code>skill</code>\nwill be called <code>team</code> for the purposes of defining the prior and handling output. The\nsubscript values themselves are defined by the use of the <code>skill</code> parameter.</p>\n\n<p>Naming the subscripts with the match is also useful for deeper parameter hierarchies.\nFor instance, this model may extend over many years, in which case we could write:</p>\n\n<pre><code>score_diff ~ normal(skill[home_team, year] - skill[away_team, year], sigma);\nskill[team, year] ~ normal(all_time_skill[team], tau);\n</code></pre>\n\n<p><code>skill</code> is now subscripted by two columns of the dataframe in two different ways,\n<code>[home_team, year]</code> and <code>[away_team, year]</code>. There will be an element of <code>skill</code>\ndefined for every combination of home team and year, and away team and year.</p>\n\n<p>The prior for the <code>[team, year]</code> element of <code>skill</code> is now a normal with mean\n<code>all_time_skill[team]</code> and standard deviation <code>tau</code>. Because <code>all_time_skill</code>\ndoes not exist and is a subscripted variable, Rat will infer that it is a parameter\nwith unique elements given by all possible values of teams.</p>\n\n<p>Matching is done by parameter position. If we had swapped the <code>year</code> and <code>team</code>\nsubscripts in the prior we would still have a valid Rat model, but the elements of the <code>team</code>\nsubscript would correspond to the unique values of year in the original dataframe!</p>\n\n<p>(Beware this:)</p>\n\n<pre><code>skill[year, team] ~ normal(all_time_skill[team], tau);\n</code></pre>\n\n<h2 id=\"constraints\">Constraints</h2>\n\n<p>The model above won't get far without a prior on <code>tau</code>. Because <code>tau</code> is a\nstandard deviation, it must be constrained to be positive.</p>\n\n<p>Rat adopts a similar constraint syntax to Stan:</p>\n\n<pre><code>score_diff ~ normal(skill[home_team], sigma);\nskill[home_team] ~ normal(0.0, tau);\ntau&lt;lower = 0.0&gt; ~ normal(0.0, 1.0);\n</code></pre>\n\n<p>The constraint goes after the parameter name but before the subscripts. Rat\nsupports a <code>lower</code>, <code>upper</code> and a combination of the two constraints.</p>\n\n<h2 id=\"transformed-parameters\">Transformed parameters</h2>\n\n<p>Rat may infer that a variable is a parameter by its use, but this parameter\ndoesn't necessarily need to be a parameter of the joint distribution sampled\nwith MCMC. Transformed parameters are immutable functions of other parameters\nthat are set in assignment statements (statements where the left and righthand\nside is separated by an <code>=</code>).</p>\n\n<p>One of the basic things transformed parameters let us do is implement a\nnon-centered parameterization. Internally Rat uses the NUTS sampler in\n<a href=\"https://github.com/blackjax-devs/blackjax\">blackjax</a>. It is useful to\nreparameterize hierarchical models for NUTS to avoid\n<a href=\"https://mc-stan.org/users/documentation/case-studies/divergences_and_bias.html\">divergences</a>.</p>\n\n<p>The eight schools data is as follows:</p>\n\n<pre><code>    y  sigma  school\n0  28     15       1\n1   8     10       2\n2  -3     16       3\n3   7     11       4\n4  -1      9       5\n5   1     11       6\n6  18     10       7\n7  12     18       8\n</code></pre>\n\n<p>The rat code for the centered eight schools model is the following:</p>\n\n<pre><code>y ~ normal(theta[school], sigma);\ntheta[school] ~ normal(mu, tau);\nmu ~ normal(0, 5);\ntau&lt;lower = 0.0&gt; ~ log_normal(0, 1);\n</code></pre>\n\n<p><code>y</code> and <code>sigma</code> come from the dataframe. Rat infers <code>theta</code> is a parameter\nwith one element for each school, and <code>mu</code> and <code>tau</code> are both scalar parameters.</p>\n\n<p>This model is difficult for NUTS to sample. The non-centered eight\nschools model is the following: </p>\n\n<pre><code>y ~ normal(theta[school], sigma);\ntheta[school] = mu + z[school] * tau;\nz[school] ~ normal(0, 1);\nmu ~ normal(0, 5);\ntau&lt;lower = 0.0&gt; ~ log_normal(0, 1);\n</code></pre>\n\n<p>The new line of code is the second -- in this case we say the elements of\n<code>theta</code> are equal to the expression on the right hand side. Transformed\nparameters are immutable, so once they are set they cannot be changed.\nSimilarly, a transformed parameter cannot be used on the righthand side of\nits own assignment.</p>\n\n<p>Variables on the right hand side of an assignment that Rat does not recognize\nwill be inferred as other parameters. In this case, <code>mu</code>, <code>tau</code>, and <code>z</code>,\nthe untransformed versions of <code>theta</code>.</p>\n\n<h2 id=\"shift-operator\">Shift operator</h2>\n\n<p>The elements of non-scalar Rat parameters are sorted with respect to the\nvalues of the subscripts (in the order of the subscripts, so the rightmost\nsubscript is sorted last). Because elements have an order, we can think\nabout a previous and next element. This is useful for time series models.</p>\n\n<p>Going back to the basketball model, we might be interested in how a team's\nskill changes year to year:</p>\n\n<pre><code>score_diff ~ normal(skill[home_team, year] - skill[away_team, year], sigma);\nskill[team, year] ~ normal(skill[team, shift(year, 1)], tau);\n</code></pre>\n\n<p>The shift of 1 on the <code>skill</code> year subscript means, for the given team, take\nthe previous year's <code>skill</code> as the mean in the prior for the current year.</p>\n\n<p>Positive shifts mean take previous values of the <code>skill</code> parameter; negative\nshifts mean take following values of the <code>skill</code> parameter. Any out of\nbounds access on the <code>skill</code> parameter is replaced with a zero.</p>\n\n<p>Multiple variables can be shifted different lengths (though each variable\ngets its own shift). The shifts are done only within groups defined by the\nunshifted parameters. That is a mouthful, but in terms of basketball example\nthis looks like:</p>\n\n<table>\n<thead>\n<tr>\n  <th><code>skill[team, year]</code></th>\n  <th><code>skill[team, shift(year, 1)]</code></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n  <td><code>skill[CHA, 2016]</code></td>\n  <td><code>0</code></td>\n</tr>\n<tr>\n  <td><code>skill[CHA, 2017]</code></td>\n  <td><code>skill[CHA, 2016]</code></td>\n</tr>\n<tr>\n  <td><code>skill[ATL, 2017]</code></td>\n  <td><code>0</code></td>\n</tr>\n</tbody>\n</table>\n\n<p>A negative shift produces a different result:</p>\n\n<table>\n<thead>\n<tr>\n  <th><code>skill[team, year]</code></th>\n  <th><code>skill[team, shift(year, -1)]</code></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n  <td><code>skill[CHA, 2016]</code></td>\n  <td><code>skill[CHA, 2017]</code></td>\n</tr>\n<tr>\n  <td><code>skill[CHA, 2017]</code></td>\n  <td><code>0</code></td>\n</tr>\n<tr>\n  <td><code>skill[ATL, 2017]</code></td>\n  <td><code>0</code></td>\n</tr>\n</tbody>\n</table>\n\n<h2 id=\"execution-order\">Execution order</h2>\n\n<p>Rat sorts statements to make sure they are evaluated in an order so that\nall transformed parameters are set before they are used. This means the user\ndoes not need to worry about statement order -- just that there are either priors\nor assignments for every parameter used in the program.</p>\n\n<h2 id=\"distributions\">Distributions</h2>\n\n<p>$\\mathcal{R}$ here means all real numbers and $\\mathcal{R}^+$ means real numbers greater than zero.</p>\n\n<table>\n<thead>\n<tr>\n  <th>Distribution</th>\n  <th>Constraints</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n  <td><code>y ~ bernoulli_logit(logit_p)</code></td>\n  <td>$y = 0$ or $y = 1$, $\\text{logit_p} \\in \\mathcal{R}$</td>\n</tr>\n<tr>\n  <td><code>y ~ cauchy(location, scale)</code></td>\n  <td>$y, \\text{location} \\in \\mathcal{R}$, $\\text{scale} \\in \\mathcal{R}^+$</td>\n</tr>\n<tr>\n  <td><code>y ~ exponential(scale)</code></td>\n  <td>$y, \\text{scale} \\in \\mathcal{R}^+$</td>\n</tr>\n<tr>\n  <td><code>y ~ log_normal(mu, sigma)</code></td>\n  <td>$\\text{mu} \\in \\mathcal{R}$, $y, \\text{sigma} \\in \\mathcal{R}^+$</td>\n</tr>\n<tr>\n  <td><code>y ~ normal(mu, sigma)</code></td>\n  <td>$y, \\text{mu} \\in \\mathcal{R}$, $\\text{sigma} \\in \\mathcal{R}^+$</td>\n</tr>\n</tbody>\n</table>\n\n<h2 id=\"functions\">Functions</h2>\n\n<ul>\n<li><code>abs(x)</code></li>\n<li><code>arccos(x)</code></li>\n<li><code>arcsin(x)</code></li>\n<li><code>arctan(x)</code></li>\n<li><code>ceil(x)</code></li>\n<li><code>cos(x)</code></li>\n<li><code>exp(x)</code></li>\n<li><code>floor(x)</code></li>\n<li><code>inverse_logit(x)</code></li>\n<li><code>log(x)</code></li>\n<li><code>logit(x)</code></li>\n<li><code>round(x)</code></li>\n<li><code>sin(x)</code></li>\n<li><code>tan(x)</code></li>\n</ul>\n\n<h2 id=\"operator-precedence-table\">Operator Precedence Table</h2>\n\n<table>\n<thead>\n<tr>\n  <th>Operator</th>\n  <th style=\"text-align:center;\">Precedence</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n  <td>function calls(<code>exp</code>, <code>log</code>, etc.)</td>\n  <td style=\"text-align:center;\">100, leftmost derivative</td>\n</tr>\n<tr>\n  <td>prefix negation(<code>-10</code>, <code>-(1+2)</code>, etc.)</td>\n  <td style=\"text-align:center;\">50</td>\n</tr>\n<tr>\n  <td><code>^</code></td>\n  <td style=\"text-align:center;\">40</td>\n</tr>\n<tr>\n  <td><code>*</code>, <code>/</code>, <code>%</code></td>\n  <td style=\"text-align:center;\">30</td>\n</tr>\n<tr>\n  <td><code>+</code>, <code>-</code></td>\n  <td style=\"text-align:center;\">10</td>\n</tr>\n</tbody>\n</table>\n\n<h1 id=\"installation-and-use\">Installation and Use</h1>\n\n<p>Rat is only available from Github:</p>\n\n<pre><code>git clone https://github.com/bbbales2/regressions\ncd regressions\npip install .\n</code></pre>\n\n<h2 id=\"command-line-interface\">Command line interface</h2>\n\n<p>Rat is a Python library, but comes with a helper script <code>rat</code> to quickly compile and\nrun models.</p>\n\n<p>For example, to fit a model <code>mrp.rat</code> with the data <code>mrp.csv</code> and save the results in\n<code>output</code> we can do:</p>\n\n<pre><code>rat mrp.rat mrp.csv output\n</code></pre>\n\n<p>Type <code>rat -h</code> for full usage info.</p>\n"}, {"fullname": "rat.fit", "modulename": "rat.fit", "qualname": "", "type": "module", "doc": "<p></p>\n"}, {"fullname": "rat.fit.Fit", "modulename": "rat.fit", "qualname": "Fit", "type": "class", "doc": "<p>Parent class for optimization/MCMC results</p>\n"}, {"fullname": "rat.fit.Fit.__init__", "modulename": "rat.fit", "qualname": "Fit.__init__", "type": "function", "doc": "<p></p>\n", "parameters": [], "funcdef": "def"}, {"fullname": "rat.fit.Fit.draws", "modulename": "rat.fit", "qualname": "Fit.draws", "type": "function", "doc": "<p>Get the draws for given parameter(s) with columns for the\nsubscripts.</p>\n\n<p>If multiple parameter names given, outer join the tables for\neach name and return that result.</p>\n\n<p>For optimizations there will only ever be one draw in the\nresults (the optimum).</p>\n", "parameters": ["self", "parameter_names"], "funcdef": "def"}, {"fullname": "rat.fit.Fit.save", "modulename": "rat.fit", "qualname": "Fit.save", "type": "function", "doc": "<p>Save results to a folder. If overwrite is true, overwrite\nexisting files and folders</p>\n", "parameters": ["self", "folder", "overwrite"], "funcdef": "def"}, {"fullname": "rat.fit.OptimizationFit", "modulename": "rat.fit", "qualname": "OptimizationFit", "type": "class", "doc": "<p>Stores optimization results</p>\n"}, {"fullname": "rat.fit.OptimizationFit.__init__", "modulename": "rat.fit", "qualname": "OptimizationFit.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "draw_dfs"], "funcdef": "def"}, {"fullname": "rat.fit.SampleFit", "modulename": "rat.fit", "qualname": "SampleFit", "type": "class", "doc": "<p>Stores draws from an MCMC calculation</p>\n"}, {"fullname": "rat.fit.SampleFit.__init__", "modulename": "rat.fit", "qualname": "SampleFit.__init__", "type": "function", "doc": "<p></p>\n", "parameters": ["self", "draw_dfs", "diag_dfs"], "funcdef": "def"}, {"fullname": "rat.fit.SampleFit.diag", "modulename": "rat.fit", "qualname": "SampleFit.diag", "type": "function", "doc": "<p>Get diagnostic dataframe for a given parameter. Diagnostics are currently\neffective sample size and rhat</p>\n", "parameters": ["self", "parameter_name"], "funcdef": "def"}, {"fullname": "rat.fit.SampleFit.save", "modulename": "rat.fit", "qualname": "SampleFit.save", "type": "function", "doc": "<p>Save the SampleFit object to a folder. If overwrite is true, then overwrite\nexisting files and use existing folders</p>\n", "parameters": ["self", "folder", "overwrite"], "funcdef": "def"}, {"fullname": "rat.fit.load", "modulename": "rat.fit", "qualname": "load", "type": "function", "doc": "<p>Load an OptimizationFit/SampleFit from the folder in which\nit was saved</p>\n", "parameters": ["folder"], "funcdef": "def"}, {"fullname": "rat.model", "modulename": "rat.model", "qualname": "", "type": "module", "doc": "<p></p>\n"}, {"fullname": "rat.model.Model", "modulename": "rat.model", "qualname": "Model", "type": "class", "doc": "<p></p>\n"}, {"fullname": "rat.model.Model.__init__", "modulename": "rat.model", "qualname": "Model.__init__", "type": "function", "doc": "<p>Create a model from a dataframe (<code>data_df</code>) and a model (specified as a string, <code>model_string</code>).</p>\n\n<p>If compile_path is not None, then write the compiled model to the given path (will only overwrite\nexisting files if the overwrite flag is true)</p>\n\n<p>The parsed_lines argument is for creating a model from an intermediate representation -- likely\ndeprecated soon.</p>\n", "parameters": ["self", "data_df", "model_string", "parsed_lines", "compile_path", "overwrite"], "funcdef": "def"}, {"fullname": "rat.model.Model.optimize", "modulename": "rat.model", "qualname": "Model.optimize", "type": "function", "doc": "<p>Maximize the log density. <code>chains</code> difference optimizations are initialized.</p>\n\n<p>An error is thrown if the different solutions are not all within tolerance of the\nmedian solution for each parameter. If only one chain is used, the tolerance is\nignored.</p>\n\n<p>If any optimization fails, retry up to <code>retries</code> number of times.</p>\n\n<p>Initialize parameters in unconstrained space uniformly [-2, 2].</p>\n", "parameters": ["self", "init", "chains", "retries", "tolerance"], "funcdef": "def"}, {"fullname": "rat.model.Model.sample", "modulename": "rat.model", "qualname": "Model.sample", "type": "function", "doc": "<p>Sample the target log density using NUTS.</p>\n\n<p>Sample using <code>chains</code> different chains with parameters initialized in unconstrained\nspace [-2, 2]. Use <code>num_warmup</code> draws to warmup and collect <code>num_draws</code> draws in each\nchain after warmup.</p>\n\n<p>Regardless of the value of <code>chains</code>, only one chain is used for warmup.</p>\n\n<p><code>target_acceptance_rate</code> is the target acceptance rate for adaptation. Should be less\nthan one and greater than zero.</p>\n", "parameters": ["self", "num_draws", "num_warmup", "chains", "init", "target_acceptance_rate"], "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();